from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
from fastsam import FastSAM, FastSAMPrompt
import cv2
import matplotlib.pyplot as plt
import numpy as np
import torch
from PIL import Image
from .base import BaseModel

class LocalFastSAMModel(BaseModel):
    def __init__(self):
        self.model = FastSAM("./FastSAM-x.pt")
        self.device = "mps" if torch.backends.mps.is_available() else "cpu"

    def run(self, image: Image) -> Image:
        everything_results = self.model(
            image, device=self.device, retina_masks=True, imgsz=512, conf=0.4, iou=0.9
        )
        prompt_process = FastSAMPrompt(image, everything_results, device=self.device)
        annotations = prompt_process.everything_prompt().detach().cpu().numpy()

        # Sort by area
        annotations = list(annotations)
        annotations.sort(key=lambda mask: np.sum(mask), reverse=True)
        # Combine masks
        image = self.combine_masks(annotations)
        return Image.fromarray(image.astype(np.uint8))

    def combine_masks(self, masks: list[np.array]) -> np.array:
        # This is from the FastSAM code repo
        for i, mask in enumerate(masks):
            mask = cv2.morphologyEx(
                mask.astype(np.uint8), cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8)
            )
            masks[i] = cv2.morphologyEx(
                mask.astype(np.uint8), cv2.MORPH_OPEN, np.ones((8, 8), np.uint8)
            )
        # Below was generated by Chat-GPT
        num_masks = len(masks)
        colors = np.random.randint(0, 256, size=(num_masks, 3))
        # Create an empty image
        image = np.zeros((masks[0].shape[0], masks[0].shape[1], 3), dtype=np.uint8)
        for idx, mask in enumerate(masks):
            # Generate a random color for each mask
            color = colors[idx]
            # Apply mask to the image
            image[mask == 1] = color
            # Find contours and add numbered labels
            contours, _ = cv2.findContours(
                (mask * 255).astype(np.uint8),
                cv2.RETR_EXTERNAL,
                cv2.CHAIN_APPROX_SIMPLE,
            )
            for i, contour in enumerate(contours):
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cX = int(M["m10"] / M["m00"])
                    cY = int(M["m01"] / M["m00"])
                    cv2.putText(
                        image,
                        str(idx + 1),
                        (cX, cY),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1,
                        (255, 255, 255),
                        2,
                    )
        return image


class LocalSAMModel(BaseModel):
    def __init__(self):
        self.sam = sam_model_registry["default"](checkpoint="./sam_vit_h_4b8939.pth")
        # Run on Metal if available (macOS) - doesn't work:
        # TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.
        # device = "mps" if torch.backends.mps.is_available() else "cpu"
        # self.sam.to(device=device)
        self.mask_generator = SamAutomaticMaskGenerator(self.sam)

    def run(self, image):
        return self.generate_segmented_image(image)

    def generate_segmented_image(self, image):  # cv2 image...
        anns = self.mask_generator.generate(image)
        mask = self.get_mask(anns)
        dst = cv2.addWeighted(mask, 0.6, mask, 0.4, 0.0)
        dst = self.add_labels(dst, anns)
        return Image.fromarray(dst.astype(np.uint8))

    def get_mask(self, anns):
        if len(anns) == 0:
            raise ValueError("List of mask is empty")
        sorted_anns = sorted(anns, key=(lambda x: x["area"]), reverse=True)
        img = np.zeros(
            (
                sorted_anns[0]["segmentation"].shape[0],
                sorted_anns[0]["segmentation"].shape[1],
                3,
            )
        )
        coords = []
        for ann in sorted_anns:
            m = ann["segmentation"]
            color_mask = np.random.random((1, 3)).tolist()[0]
            color_mask = [int(c * 255) for c in color_mask]
            img[m] = color_mask
            coords.append(ann["point_coords"][0])
        return img.astype(np.uint8)

    def add_labels(self, img, anns):
        for i, ann in enumerate(anns):
            cx, cy = ann["point_coords"][0]
            cv2.putText(
                img,
                str(i),
                (int(cx) - 5, int(cy) + 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (255, 255, 255),
                5,
            )
        return img
